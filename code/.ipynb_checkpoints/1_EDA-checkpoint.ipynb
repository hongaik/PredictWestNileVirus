{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 4: Predicting West Nile Virus in Mosquitoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import re\n",
    "import datetime\n",
    "import random\n",
    "import pickle\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from matplotlib import dates, cm\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "Unable to open ../assets/geo_export_a6957f22-b168-4cee-b03c-0bcc9815308c.shx or ../assets/geo_export_a6957f22-b168-4cee-b03c-0bcc9815308c.SHX. Set SHAPE_RESTORE_SHX config option to YES to restore or create it.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mfiona\\_shim.pyx:83\u001b[0m, in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: Unable to open ../assets/geo_export_a6957f22-b168-4cee-b03c-0bcc9815308c.shx or ../assets/geo_export_a6957f22-b168-4cee-b03c-0bcc9815308c.SHX. Set SHAPE_RESTORE_SHX config option to YES to restore or create it.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import shape file for city of Chicago\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# downloaded from https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-City/ewy2-6yfk\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m street_map \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../assets/geo_export_a6957f22-b168-4cee-b03c-0bcc9815308c.shp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\geoenv\\lib\\site-packages\\geopandas\\io\\file.py:201\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m reader(path_or_bytes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[0;32m    202\u001b[0m \n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# In a future Fiona release the crs attribute of features will\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;66;03m# no longer be a dict, but will behave like a dict. So this should\u001b[39;00m\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;66;03m# be forwards compatible\u001b[39;00m\n\u001b[0;32m    206\u001b[0m         crs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    207\u001b[0m             features\u001b[38;5;241m.\u001b[39mcrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    208\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m features\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mcrs\n\u001b[0;32m    209\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[0;32m    210\u001b[0m         )\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;66;03m# handle loading the bounding box\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\geoenv\\lib\\site-packages\\fiona\\env.py:408\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local\u001b[38;5;241m.\u001b[39m_env:\n\u001b[1;32m--> 408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\.conda\\envs\\geoenv\\lib\\site-packages\\fiona\\__init__.py:256\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 256\u001b[0m     c \u001b[38;5;241m=\u001b[39m Collection(path, mode, driver\u001b[38;5;241m=\u001b[39mdriver, encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    257\u001b[0m                    layer\u001b[38;5;241m=\u001b[39mlayer, enabled_drivers\u001b[38;5;241m=\u001b[39menabled_drivers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m schema:\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;66;03m# Make an ordered dict of schema properties.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\geoenv\\lib\\site-packages\\fiona\\collection.py:162\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[1;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[1;32mfiona\\ogrext.pyx:540\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\_shim.pyx:90\u001b[0m, in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDriverError\u001b[0m: Unable to open ../assets/geo_export_a6957f22-b168-4cee-b03c-0bcc9815308c.shx or ../assets/geo_export_a6957f22-b168-4cee-b03c-0bcc9815308c.SHX. Set SHAPE_RESTORE_SHX config option to YES to restore or create it."
     ]
    }
   ],
   "source": [
    "# import shape file for city of Chicago\n",
    "# downloaded from https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-City/ewy2-6yfk\n",
    "street_map = gpd.read_file('../assets/geo_export_a6957f22-b168-4cee-b03c-0bcc9815308c.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('assets/train.csv/train.csv')\n",
    "train['Date'] = pd.to_datetime(train['Date'])\n",
    "train['year'] = train['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(train.groupby(train['Date'].dt.year)['WnvPresent'].value_counts(normalize=True), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Date'].dt.year.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a U-shaped pattern for the positivity rate - 6% in 2007, 1% in 2009, 3% in 2011 and 10% in 2013. This explains the same shape for the number of tests done over the years, which probably correlates with the actual number of reported WNV cases over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(train.groupby(train['Date'].dt.month)['WnvPresent'].value_counts(normalize=True), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Date'].dt.month.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More tests are done in Sep-Oct which also yields higher positivity rate, probably due to higher reported numbers of WNV cases. Because of the lack of testing data in other months, predictions for those months may not be accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a point for every lat-long combination\n",
    "geometry = [Point(xy) for xy in zip(train['Longitude'], train['Latitude'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gpd DataFrame\n",
    "geo_train = gpd.GeoDataFrame(train,\n",
    "                            crs={'init': 'epsg:4326'},\n",
    "                             geometry=geometry)\n",
    "geo_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby address to aggregate \"density\" of WNV at each location. Density can be high due to many detections over time or a single detection\n",
    "# with large concentration of positive mosquitos, hence across time and batch\n",
    "geo_train_groupby = geo_train.dissolve(by='Address', aggfunc='sum')\n",
    "geo_train_groupby.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count of WNVPresent indicates the density. As the dataset consists  of multiple years and multiple batches, the value has no interpretable meaning but provides a relative value about its \"hotness\" as a cluster. For example, 4 could mean that there were 4 batches of mosquitos returning positive in one day, or 1 batch of mosquito every year over 4 years. Hence, the value provides a rough sense of how prone it is to WNV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where are the traps and which traps have returned positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,12), nrows=1, ncols=2)\n",
    "\n",
    "# Chicago background\n",
    "street_map.plot(ax=ax[0], alpha=0.4, color='grey')\n",
    "street_map.plot(ax=ax[1], alpha=0.4, color='grey')\n",
    "\n",
    "# Plot locations where WNV is detected. Size of marker indicates density\n",
    "geo_train_groupby[geo_train_groupby['WnvPresent']>0].plot(ax=ax[1], color='red', marker='o', label='Positive', markersize = (geo_train_groupby[geo_train_groupby['WnvPresent']>0]['WnvPresent']*3).values)\n",
    "\n",
    "# Plot locations of all traps\n",
    "geo_train_groupby.plot(ax=ax[0], markersize=10, color='green', marker='^', label='Trap Locations')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Location of all traps - All Years')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Location of of traps with positive returns - All Years')\n",
    "\n",
    "fig.savefig('charts/01.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No discernible pattern of spread, though some neighborhoods have a higher density of infected mosquitos. Most traps return positive at least once throughout the years. The two densest clusters is at ORD airport and near a water reclamation plant at South Doty Avenue.\n",
    "\n",
    "Airplanes are known to be a vessel for mosquitos to travel. Given that ORD airport is international and has a much higher passenger flow than Midway airport, this could be reasons why a cluster could form there. It could also receive passengers from all over the world, some of whom may already been infected by the virus.\n",
    "\n",
    "As for the water reclamation plant, due to the fact that it is sited near large bodies of water, mosquito breeding grounds could be abundant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is there a pattern of positive returns over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 1 dataframe, 1 for each year\n",
    "geo_train_groupby_2007_WNV = geo_train[geo_train['Date'].dt.year==2007].dissolve(by='Address', aggfunc='sum')\n",
    "geo_train_groupby_2007_WNV = geo_train_groupby_2007_WNV[geo_train_groupby_2007_WNV['WnvPresent'] > 0]\n",
    "\n",
    "geo_train_groupby_2009_WNV = geo_train[geo_train['Date'].dt.year==2009].dissolve(by='Address', aggfunc='sum')\n",
    "geo_train_groupby_2009_WNV = geo_train_groupby_2009_WNV[geo_train_groupby_2009_WNV['WnvPresent'] > 0]\n",
    "\n",
    "geo_train_groupby_2011_WNV = geo_train[geo_train['Date'].dt.year==2011].dissolve(by='Address', aggfunc='sum')\n",
    "geo_train_groupby_2011_WNV = geo_train_groupby_2011_WNV[geo_train_groupby_2011_WNV['WnvPresent'] > 0]\n",
    "\n",
    "geo_train_groupby_2013_WNV = geo_train[geo_train['Date'].dt.year==2013].dissolve(by='Address', aggfunc='sum')\n",
    "geo_train_groupby_2013_WNV = geo_train_groupby_2013_WNV[geo_train_groupby_2013_WNV['WnvPresent'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(18,18), nrows=1, ncols=4)\n",
    "street_map.plot(ax=ax[0], alpha=0.4, color='grey')\n",
    "street_map.plot(ax=ax[1], alpha=0.4, color='grey')\n",
    "street_map.plot(ax=ax[2], alpha=0.4, color='grey')\n",
    "street_map.plot(ax=ax[3], alpha=0.4, color='grey')\n",
    "\n",
    "geo_train_groupby_2007_WNV.plot(ax=ax[0], markersize=(geo_train_groupby_2007_WNV['WnvPresent']*5).values, color='red', marker='o')\n",
    "ax[0].set_title('Positive Areas - 2007')\n",
    "\n",
    "geo_train_groupby_2009_WNV.plot(ax=ax[1], markersize=(geo_train_groupby_2009_WNV['WnvPresent']*5).values, color='red', marker='o')\n",
    "ax[1].set_title('Positive Areas - 2009')\n",
    "\n",
    "geo_train_groupby_2011_WNV.plot(ax=ax[2], markersize=(geo_train_groupby_2011_WNV['WnvPresent']*5).values, color='red', marker='o')\n",
    "ax[2].set_title('Positive Areas - 2011')\n",
    "\n",
    "geo_train_groupby_2013_WNV.plot(ax=ax[3], markersize=(geo_train_groupby_2013_WNV['WnvPresent']*5).values, color='red', marker='o')\n",
    "ax[3].set_title('Positive Areas - 2013')\n",
    "\n",
    "fig.savefig('charts/02.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was quite the outbreak in starting in 2007, with concentrations in the north and south of Chicago. Miraculously, positivity rates plunged in 2009, but continued to grow since then, especially ORD airport in the North-West, where the cluster grew larger over time.\n",
    "\n",
    "It seems that there is some sort of cyclical pattern. It cannot be weather because there is no substantial difference in climate in 2009 and 2011 compared to 2007 and 2013 driving the infection. This is likely man-made effect where perhaps due to some drastic measures undertaken by the city (what?) to curb the virus transmission after 2007.\n",
    "\n",
    "Variable: WNV Density equal to value at that address in the current/preceding year. Current year for training the model with the training data, preceding year for predictions on the test dataset.\n",
    "\n",
    "This is to account for the time - a hotspot in 2007 may no longer be a hotspot in 2013. That said, there could still be fluctuations within months, weeks and days, but we will not dive at the level to keep our model simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnv_density_year = geo_train.dissolve(by=['year', 'Address'], aggfunc='sum')['WnvPresent']\n",
    "wnv_density_year.to_csv('assets/processed_data/wnv_density_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does higher number of mosquitos affect probability of WNV present?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=1, ncols=2, constrained_layout=True, figsize=(10,4))\n",
    "sns.histplot(data=geo_train[geo_train['WnvPresent']==1], binwidth=1, x='NumMosquitos', ax=ax[0])\n",
    "ax[0].set_title('Batch size distribution where WNV is present')\n",
    "sns.histplot(data=geo_train[geo_train['WnvPresent']==0], binwidth=1, x='NumMosquitos', ax=ax[1])\n",
    "ax[1].set_title('Batch size distribution where WNV is absent')\n",
    "\n",
    "fig.savefig('charts/03.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the left graph, most of the WNV occurs when batch size is 50. This is expected, since higher numbers of mosquitos means higher likelihood of disease transmission. Unfortunately, we cannot use this as a predictor as this information is not available in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which months have higher WNV occurrences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_groupby = geo_train.groupby(geo_train['Date'].dt.month)['WnvPresent'].sum().reset_index()\n",
    "date_groupby['Date'] = date_groupby['Date'].map({5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct'})\n",
    "sns.barplot(data=date_groupby, x='Date', y='WnvPresent')\n",
    "\n",
    "plt.savefig('charts/04.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jul, Aug and Sep are the hottest months for transmission of WNV, as we saw earlier. This is probably attributed to weather conditions (see below) where these months tend to be warmer and more humid.\n",
    "\n",
    "Variable: month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which species of mosquitos carry WNV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groupby = geo_train.groupby('Species')['WnvPresent'].sum().reset_index()\n",
    "sns.barplot(data=species_groupby, y='Species', x='WnvPresent', orient='h')\n",
    "plt.savefig('charts/05.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Pipiens and Restuans subspecies have been detected with the virus. However this doesn't mean that the other subspecies are unable to carry the virus. If this turns out to be so in future, our model would be extremely poor at predicting these subspecies because it has never observed such cases before in our training data.\n",
    "\n",
    "Variable: Species of mosquito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spray = pd.read_csv('assets/spray.csv/spray.csv')\n",
    "spray['Date'] = pd.to_datetime(spray['Date'])\n",
    "spray = spray[spray['Latitude'] < 42.3] # remove outliers outside of Chicago\n",
    "spray.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spray['Date'].dt.month.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alot more sprays done in August - expected since transmission spikes in August."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_spray = [Point(xy) for xy in zip(spray['Longitude'], spray['Latitude'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_spray = gpd.GeoDataFrame(spray,\n",
    "                            crs={'init': 'epsg:4326'},\n",
    "                             geometry=geometry_spray)\n",
    "geo_spray.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_spray_2011 = geo_spray[geo_spray['Date'].dt.year==2011]\n",
    "geo_spray_2013 = geo_spray[geo_spray['Date'].dt.year==2013]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spray juxtaposed Positive Traps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(14,14), ncols=2)\n",
    "street_map.plot(ax=ax[0], alpha=0.4, color='grey')\n",
    "street_map.plot(ax=ax[1], alpha=0.4, color='grey')\n",
    "\n",
    "geo_train_groupby_2011_WNV.plot(ax=ax[0], markersize=(geo_train_groupby_2011_WNV['WnvPresent']*5).values, color='red', marker='o', label='Positive')\n",
    "geo_spray_2011.plot(ax=ax[0], markersize=3, color='blue', marker='x', label='Spray Locations', alpha=0.2)\n",
    "geo_train_groupby.plot(ax=ax[0], markersize=10, color='green', marker='^', label='Trap Locations')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Locations of sprays juxtaposed against Positive Traps, 2011')\n",
    "\n",
    "geo_train_groupby_2013_WNV.plot(ax=ax[1], markersize=(geo_train_groupby_2013_WNV['WnvPresent']*5).values, color='red', marker='o', label='Positive')\n",
    "geo_spray_2013.plot(ax=ax[1], markersize=3, color='blue', marker='x', label='Spray Locations', alpha=0.2)\n",
    "geo_train_groupby.plot(ax=ax[1], markersize=10, color='green', marker='^', label='Trap Locations')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Locations of sprays juxtaposed against Positive Traps, 2013')\n",
    "\n",
    "fig.savefig('charts/06.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in 2011, spraying was only conducted in 1 particular neighborhood, wherelse in 2013 efforts expanded significantly to more neighborhoods. This suggests a reactive approach taken by city council - to only step up spraying when positivity rates increase and/or actual reported cases increase. We can see that spraying does help somewhat, where the traps within the spray zone turn up negative after spraying.\n",
    "\n",
    "Variable: whether location is near a coordinate earmarked for spraying. Since we do not have spray data for all the years, we can only assume that these locations were sprayed because the authorities had some intelligence that these are the hot spots.\n",
    "\n",
    "While spraying would definitely have a strong correlation as to whether WNV is present, this variable may or may not be useful due to the time lag in making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take distinct latitude and longitude - if present, shows that the location has been earmarked for spraying, indicating hot spots\n",
    "spray[['Latitude', 'Longitude']].drop_duplicates(subset=['Latitude', 'Longitude']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for feature engineering later\n",
    "spray[['Latitude', 'Longitude']].drop_duplicates(subset=['Latitude', 'Longitude']).to_csv('assets/processed_data/spray_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Wikipedia](https://en.wikipedia.org/wiki/West_Nile_virus), we know that the epidemiology of WNV is dependent on:\n",
    "- Humidity (higher favors WNV)\n",
    "- Temperature (higher favors mosquito replication, WNV replication and efficiency)\n",
    "- Precipitation (higher favors WNV)\n",
    "- Wind Speed (higher favors dispersal of mosquitos)\n",
    "\n",
    "Variables:\n",
    "- DewPoint\n",
    "- WetBulb\n",
    "- Tavg\n",
    "- AvgSpeed\n",
    "- PrecipTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill missing data. For columns with missing data, we will use the average data of D-1 and D+1. If D-1 and D+1 also results\n",
    "# in missing, then go back/forward one more day until non-missing data is available\n",
    "def find_average_value(main_df, index, column):\n",
    "    \n",
    "    station_missing = index['Station']\n",
    "    \n",
    "    # D-1, or when data is available\n",
    "    i = -1\n",
    "    date_missing_prev = index['Date'] + pd.Timedelta(days=-1)\n",
    "    while main_df[(main_df['Station']==station_missing) & (main_df['Date']==date_missing_prev)][column].values[0] == 'M':\n",
    "        i -= 1\n",
    "        date_missing_prev = index['Date'] + pd.Timedelta(days=i)\n",
    "    \n",
    "    # D+1, or when data is available\n",
    "    j = 1\n",
    "    date_missing_next = index['Date'] + pd.Timedelta(days=1)\n",
    "    while main_df[(main_df['Station']==station_missing) & (main_df['Date']==date_missing_next)][column].values[0] == 'M':\n",
    "        j += 1\n",
    "        date_missing_next = index['Date'] + pd.Timedelta(days=j)\n",
    "        \n",
    "    # value of the column at D-x    \n",
    "    prev_row_value = main_df[(main_df['Station']==station_missing) & (main_df['Date']==date_missing_prev)][column].values[0]\n",
    "    # value of the column at D+x\n",
    "    next_row_value = main_df[(main_df['Station']==station_missing) & (main_df['Date']==date_missing_next)][column].values[0]\n",
    "\n",
    "    # average of both values\n",
    "    return (float(prev_row_value) + float(next_row_value))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('assets/weather.csv/weather.csv')\n",
    "weather['Date'] = pd.to_datetime(weather['Date'])\n",
    "\n",
    "# Fill non-numeric values\n",
    "# If T, replace with 0. If M, replace with function defined earlier\n",
    "weather['PrecipTotal'] = weather['PrecipTotal'].apply(lambda x: 0 if x == '  T' else x)\n",
    "weather['Tavg'] = weather.apply(lambda x: (float(x['Tmax']) + float(x['Tmin']))/2 if x['Tavg'] == 'M' else x['Tavg'], axis=1)\n",
    "weather['WetBulb'] = weather.apply(lambda x: find_average_value(weather, x, 'WetBulb') if x['WetBulb'] == 'M' else x['WetBulb'], axis=1)\n",
    "weather['PrecipTotal'] = weather.apply(lambda x: find_average_value(weather, x, 'PrecipTotal') if x['PrecipTotal'] == 'M' else x['PrecipTotal'], axis=1)\n",
    "weather['AvgSpeed'] = weather.apply(lambda x: find_average_value(weather, x, 'AvgSpeed') if x['AvgSpeed'] == 'M' else x['AvgSpeed'], axis=1)\n",
    "\n",
    "# Convert to float\n",
    "weather['DewPoint'] = weather['DewPoint'].astype(float)\n",
    "weather['WetBulb'] = weather['WetBulb'].astype(float)\n",
    "weather['Tavg'] = weather['Tavg'].astype(float)\n",
    "weather['PrecipTotal'] = weather['PrecipTotal'].astype(float)\n",
    "weather['AvgSpeed'] = weather['AvgSpeed'].astype(float)\n",
    "\n",
    "# split into station 1 and 2 to see if there are substantial differences in readings\n",
    "weather1 = weather[weather['Station']==1]\n",
    "weather1['yearmonth'] = weather1['Date'].values.astype('datetime64[M]')\n",
    "weather1['Latitude'] = 41.995\n",
    "weather1['Longitude'] = -87.933\n",
    "\n",
    "weather2 = weather[weather['Station']==2]\n",
    "weather2['yearmonth'] = weather2['Date'].values.astype('datetime64[M]')\n",
    "weather2['Latitude'] = 41.786\n",
    "weather2['Longitude'] = -87.752"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather1_groupby = weather1.groupby('yearmonth').agg({\n",
    "                                                        'DewPoint': 'mean',\n",
    "                                                        'WetBulb': 'mean',\n",
    "                                                        'Tavg': 'mean',\n",
    "                                                        'PrecipTotal': 'sum',\n",
    "                                                        'AvgSpeed': 'mean'\n",
    "                                                    })\n",
    "weather1_groupby.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find monthly weather statistics, since daily might result in alot of variance which is not very useful\n",
    "weather2_groupby = weather2.groupby('yearmonth').agg({\n",
    "                                                        'DewPoint': 'mean',\n",
    "                                                        'WetBulb': 'mean',\n",
    "                                                        'Tavg': 'mean',\n",
    "                                                        'PrecipTotal': 'sum',\n",
    "                                                        'AvgSpeed': 'mean'\n",
    "                                                    })\n",
    "weather2_groupby.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(16,12), nrows=5, sharex=True, constrained_layout=True)\n",
    "fig.suptitle('Station 1 Readings', fontsize=20)\n",
    "\n",
    "# create array of colors, 1 for each year, to separate bars by year\n",
    "yrs = np.unique(weather1_groupby.index.year)\n",
    "c = cm.get_cmap('tab20', len(yrs))\n",
    "yrClr = np.zeros((len(weather1_groupby.index.year),4))\n",
    "for i, v in enumerate(yrs): \n",
    "    yrClr[weather1_groupby.index.year==v,:]=c.colors[i,:]\n",
    "\n",
    "ax[0] = weather1_groupby['DewPoint'].plot(kind='bar', color=yrClr, ax=ax[0])\n",
    "ax[0].set_title('Monthly Average DewPoint')\n",
    "\n",
    "ax[1] = weather1_groupby['WetBulb'].plot(kind='bar', color=yrClr, ax=ax[1])\n",
    "ax[1].set_title('Monthly Average WetBulb')\n",
    "\n",
    "ax[2] = weather1_groupby['Tavg'].plot(kind='bar', color=yrClr, ax=ax[2])\n",
    "ax[2].set_title('Monthly Average Temperature')\n",
    "\n",
    "ax[3] = weather1_groupby['PrecipTotal'].plot(kind='bar', color=yrClr, ax=ax[3])\n",
    "ax[3].set_title('Monthly Total Precipitation')\n",
    "\n",
    "ax[4] = weather1_groupby['AvgSpeed'].plot(kind='bar', color=yrClr, ax=ax[4])\n",
    "ax[4].set_title('Monthly Average WindSpeed')\n",
    "\n",
    "fig.savefig('charts/07.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(16,12), nrows=5, sharex=True, constrained_layout=True)\n",
    "fig.suptitle('Station 2 Readings', fontsize=20)\n",
    "\n",
    "yrs = np.unique(weather2_groupby.index.year)\n",
    "c = cm.get_cmap('tab20', len(yrs))\n",
    "yrClr = np.zeros((len(weather2_groupby.index.year),4))\n",
    "for i, v in enumerate(yrs): \n",
    "    yrClr[weather2_groupby.index.year==v,:]=c.colors[i,:]\n",
    "\n",
    "ax[0] = weather2_groupby['DewPoint'].plot(kind='bar', color=yrClr, ax=ax[0])\n",
    "ax[0].set_title('Monthly Average DewPoint')\n",
    "\n",
    "ax[1] = weather2_groupby['WetBulb'].plot(kind='bar', color=yrClr, ax=ax[1])\n",
    "ax[1].set_title('Monthly Average WetBulb')\n",
    "\n",
    "ax[2] = weather2_groupby['Tavg'].plot(kind='bar', color=yrClr, ax=ax[2])\n",
    "ax[2].set_title('Monthly Average Temperature')\n",
    "\n",
    "ax[3] = weather2_groupby['PrecipTotal'].plot(kind='bar', color=yrClr, ax=ax[3])\n",
    "ax[3].set_title('Monthly Total Precipitation')\n",
    "\n",
    "ax[4] = weather2_groupby['AvgSpeed'].plot(kind='bar', color=yrClr, ax=ax[4])\n",
    "ax[4].set_title('Monthly Average WindSpeed')\n",
    "\n",
    "fig.savefig('charts/08.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dewpoint, Wetbulb and Temperature show a very cyclical monthly pattern, peaking around Jul-Aug. This corroborates with the earlier hypothesis that higher humidity and temperature favors WNV transmission, which is also what we observe earlier, where the most WNV found was in Aug.\n",
    "\n",
    "Precipitation is a little more volatile and unpredictable, with no clear pattern. This could be due to climate change as well.\n",
    "\n",
    "Windspeed follows a U shape pattern, where winds are weakest around August. Wind only serves as a dispersal mechanism, and perhaps the earlier months of windy conditions helped to disperse the mosquitos, and when the atmosphere is less windy, mosquitos are able to set up breeding grounds.\n",
    "\n",
    "Dewpoint, Wetbulb and Temperature are likely to be good predictors of WNV.\n",
    "\n",
    "Variable: Check average (weather indicator) of the preceding 30 days. Since there is no substantial difference between the readings of the 2 weather stations (expected, given its close proximity), we will take the average readings for any given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take average readings of 2 stations\n",
    "weather_combined = weather.groupby('Date')[['Tavg', 'DewPoint', 'WetBulb', 'PrecipTotal', 'AvgSpeed']].mean()\n",
    "weather_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for feature engineering later\n",
    "weather_combined.to_csv('assets/processed_data/weather_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
